# ì½”ë“œ ì•„í‚¤í…ì²˜ ìƒì„¸ ê°€ì´ë“œ

## ğŸ—ï¸ ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
DNN_channel_estimation_training/
â”œâ”€â”€ ğŸ¯ ì£¼ìš” ì‹¤í–‰ íŒŒì¼
â”‚   â”œâ”€â”€ engine.py              # ê¸°ë³¸ ë² ì´ìŠ¤ ëª¨ë¸ í›ˆë ¨
â”‚   â”œâ”€â”€ engine_v4.py           # v4 ë² ì´ìŠ¤ ëª¨ë¸ í›ˆë ¨ (ì‹ ê·œ)
â”‚   â”œâ”€â”€ Transfer_v4.py         # LoRA ì „ì´í•™ìŠµ
â”‚   â””â”€â”€ simple_model_test.py   # ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ ğŸ§  ëª¨ë¸ ì•„í‚¤í…ì²˜
â”‚   â”œâ”€â”€ model/estimator.py     # ê¸°ë³¸ ì±„ë„ ì¶”ì • ëª¨ë¸
â”‚   â”œâ”€â”€ model/estimator_v4.py  # v4 ì±„ë„ ì¶”ì • ëª¨ë¸ (LoRA ëŒ€ì‘)
â”‚   â”œâ”€â”€ model/transformer.py   # ê¸°ë³¸ Transformer
â”‚   â””â”€â”€ model/transformer_v4.py # v4 Transformer (ë¶„ë¦¬ëœ projection)
â”œâ”€â”€ âš™ï¸ ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ config/config.yaml                 # ê¸°ë³¸ ëª¨ë¸ í›ˆë ¨ ì„¤ì •
â”‚   â”œâ”€â”€ config/config_transfer_v4.yaml     # LoRA ì „ì´í•™ìŠµ ì„¤ì •
â”‚   â”œâ”€â”€ config/config_transfer_v4_InF.yaml # InF íŠ¹í™” ì„¤ì •
â”‚   â””â”€â”€ config/config_transfer_v4_RMa.yaml # RMa íŠ¹í™” ì„¤ì •
â”œâ”€â”€ ğŸ“Š ë°ì´í„° ì²˜ë¦¬
â”‚   â”œâ”€â”€ dataset.py             # ë°ì´í„°ì…‹ ë¡œë”
â”‚   â””â”€â”€ dataset/PDP_processed/ # ì „ì²˜ë¦¬ëœ ì±„ë„ ë°ì´í„°
â””â”€â”€ ğŸ“‹ ë¬¸ì„œí™”
    â””â”€â”€ docs/                  # ê¸°ìˆ  ë¬¸ì„œ ëª¨ìŒ
```

## ğŸ”„ ë°ì´í„° í”Œë¡œìš°

### 1. í›ˆë ¨ ë°ì´í„° í”Œë¡œìš°
```mermaid
graph TD
    A[PDP_processed/*.mat] --> B[ChannelDataset]
    B --> C[DataLoader]
    C --> D[ë³µì†Œìˆ˜ â†’ ì‹¤ìˆ˜ë¶€/í—ˆìˆ˜ë¶€ ë¶„ë¦¬]
    D --> E[Estimator_v4]
    E --> F[ì±„ë„ ì¶”ì • ê²°ê³¼]
    F --> G[NMSE ì†ì‹¤ ê³„ì‚°]
    G --> H[ì—­ì „íŒŒ & ìµœì í™”]
```

### 2. ì „ì´í•™ìŠµ í”Œë¡œìš°  
```mermaid
graph TD
    A[Large_estimator_v4_base.pt] --> B[Estimator_v4 ë¡œë“œ]
    B --> C[LoRA ë ˆì´ì–´ ì£¼ì…]
    C --> D[ë² ì´ìŠ¤ íŒŒë¼ë¯¸í„° ë™ê²°]
    D --> E[LoRA íŒŒë¼ë¯¸í„°ë§Œ í›ˆë ¨]
    E --> F[ë³‘í•©ëœ ëª¨ë¸ ì €ì¥]
```

## ğŸ§  ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¹„êµ

### Estimator vs Estimator_v4 êµ¬ì¡° ì°¨ì´

#### Estimator (ê¸°ë³¸ ëª¨ë¸)
```python
# í†µí•©ëœ MultiheadAttention ì‚¬ìš©
self.mha = MultiheadAttention(
    embed_dim=d_model, 
    num_heads=n_head,
    # ë‚´ë¶€ì ìœ¼ë¡œ q,k,v projection í†µí•© ê´€ë¦¬
)
# ê°€ì¤‘ì¹˜ í‚¤: ch_tf._layers.0.mha.q_proj_weight
```

#### Estimator_v4 (LoRA ëŒ€ì‘)
```python  
# ë¶„ë¦¬ëœ projection layers
self.mha_q_proj = Linear(d_model, d_model)  # Q projection
self.mha_k_proj = Linear(d_model, d_model)  # K projection  
self.mha_v_proj = Linear(d_model, d_model)  # V projection
self.mha = MultiheadAttention(...)          # ì‹¤ì œ attention ê³„ì‚°

# ê°€ì¤‘ì¹˜ í‚¤: ch_tf._layers.0.mha_q_proj.weight
```

### LoRA íƒ€ê²Ÿ ëª¨ë“ˆ ë§¤í•‘
```yaml
target_modules: [
  "mha_q_proj",     # Query projection
  "mha_k_proj",     # Key projection  
  "mha_v_proj",     # Value projection
  "out_proj",       # Output projection
  "ffnn_linear1",   # FFN ì²« ë²ˆì§¸ ë ˆì´ì–´
  "ffnn_linear2"    # FFN ë‘ ë²ˆì§¸ ë ˆì´ì–´
]
```

## âš™ï¸ ì„¤ì • ì‹œìŠ¤í…œ êµ¬ì¡°

### config.yaml ê³„ì¸µ êµ¬ì¡°
```yaml
dataset:           # ë°ì´í„°ì…‹ ê´€ë ¨ ì„¤ì •
  channel_type: [] # ì‚¬ìš©í•  ì±„ë„ íƒ€ì…
  batch_size: 32   # ë°°ì¹˜ í¬ê¸°
  # ... ê¸°íƒ€ ë°ì´í„° ì„¤ì •

training:          # í›ˆë ¨ ê´€ë ¨ ì„¤ì •  
  lr: 0.0001      # í•™ìŠµë¥ 
  optimizer: Adam  # ì˜µí‹°ë§ˆì´ì €
  device: cuda:0   # ë””ë°”ì´ìŠ¤
  # ... ê¸°íƒ€ í›ˆë ¨ ì„¤ì •

ch_estimation:     # ëª¨ë¸ ì•„í‚¤í…ì²˜ ì„¤ì •
  transformer:     # Transformer êµ¬ì¡°
    num_layers: 4  # ë ˆì´ì–´ ìˆ˜
    d_model: 128   # ëª¨ë¸ ì°¨ì›
    # ... ê¸°íƒ€ ëª¨ë¸ ì„¤ì •
  
  peft:           # LoRA ì„¤ì • (Transfer_v4.py ì „ìš©)
    r: 8          # LoRA rank
    lora_alpha: 8 # LoRA scaling
    # ... ê¸°íƒ€ LoRA ì„¤ì •
```

## ğŸ”§ í•µì‹¬ í´ë˜ìŠ¤ êµ¬ì¡°

### Engine_v4 í´ë˜ìŠ¤
```python
class Engine_v4:
    def __init__(self, conf_file):
        # ì„¤ì • ë¡œë“œ & í™˜ê²½ ì´ˆê¸°í™”
        self._conf = yaml.safe_load(conf_file)
        self._device = self._conf['training']['device']
        
        # ëª¨ë¸ & ë°ì´í„° ì´ˆê¸°í™”
        self._estimator = Estimator_v4(conf_file)
        self._dataset, self._dataloader = get_dataset_and_dataloader()
        
        # ì˜µí‹°ë§ˆì´ì € ì„¤ì •
        self.set_optimizer()
    
    def set_optimizer(self):
        # ì„¤ì • ê¸°ë°˜ ì˜µí‹°ë§ˆì´ì € ì„ íƒ
        optimizer_type = self._conf['training']['optimizer']
        # Adam/AdamW/SGD ì§€ì›
        
    def train(self):
        # ë©”ì¸ í›ˆë ¨ ë£¨í”„
        for it, data in enumerate(self._dataloader):
            # Forward pass
            ch_est, _ = self._estimator(rx_signal)
            
            # Loss ê³„ì‚° (NMSE)
            ch_loss = self.calculate_nmse_loss(ch_est, ch_true)
            
            # Backward pass & ìµœì í™”
            self._ch_optimizer.zero_grad()
            ch_loss.backward()
            self._ch_optimizer.step()
```

### TransferLearningEngine í´ë˜ìŠ¤ (Transfer_v4.py)
```python
class TransferLearningEngine:
    def load_model(self):
        # v4 ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ
        self._estimator = Estimator_v4(self._conf_file)
        
        # LoRA ì„¤ì • ì ìš©
        lora_config = LoraConfig(r=8, lora_alpha=8, ...)
        self._estimator = get_peft_model(self._estimator, lora_config)
        
    def save_combined_model_as_pt(self):
        # LoRA ê°€ì¤‘ì¹˜ë¥¼ ë² ì´ìŠ¤ ëª¨ë¸ì— ë³‘í•©
        merged_model = self._estimator.merge_and_unload()
        
        # engine.py í˜¸í™˜ í˜•íƒœë¡œ ë³€í™˜ í›„ ì €ì¥
        torch.save(merged_model, save_path)
```

## ğŸ”„ ìƒí˜¸ ì˜ì¡´ì„± ê·¸ë˜í”„

```mermaid
graph TD
    A[config.yaml] --> B[engine_v4.py]
    B --> C[Estimator_v4]
    C --> D[Large_estimator_v4_base.pt]
    
    E[config_transfer_v4.yaml] --> F[Transfer_v4.py] 
    F --> C
    D --> F
    F --> G[Large_estimator_PreLN_2_InF.pt]
    
    H[simple_model_test.py] --> D
    H --> G
    H --> I[ì„±ëŠ¥ ë¹„êµ ê²°ê³¼]
```

## âš¡ ì„±ëŠ¥ ìµœì í™” í¬ì¸íŠ¸

### 1. ë©”ëª¨ë¦¬ ìµœì í™”
```python
# ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ…
torch.utils.checkpoint.checkpoint(layer, input)

# Mixed Precision í›ˆë ¨
from torch.cuda.amp import autocast, GradScaler
scaler = GradScaler()
```

### 2. ê³„ì‚° ìµœì í™”
```python
# íš¨ìœ¨ì ì¸ ì–´í…ì…˜ ê³„ì‚°
torch.nn.functional.scaled_dot_product_attention()

# ì»´íŒŒì¼ ìµœì í™” (PyTorch 2.0+)
model = torch.compile(model)
```

### 3. I/O ìµœì í™”
```python
# ë°ì´í„° ë¡œë” ë©€í‹° í”„ë¡œì„¸ì‹±
DataLoader(dataset, num_workers=4, pin_memory=True)

# ë¹„ë™ê¸° ë°ì´í„° ì „ì†¡
data = data.to(device, non_blocking=True)
```

## ğŸ› ë””ë²„ê¹… ê°€ì´ë“œ

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

#### 1. CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
batch_size: 16  # 32 â†’ 16

# ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ì‚¬ìš©
if (step + 1) % accumulation_steps == 0:
    optimizer.step()
    optimizer.zero_grad()
```

#### 2. ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨
```python
# strict=False ëŒ€ì‹  í‚¤ ë§¤í•‘ í™•ì¸
missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)
print(f"Missing: {missing_keys}")
print(f"Unexpected: {unexpected_keys}")
```

#### 3. LoRA íŒŒë¼ë¯¸í„° ë™ê²° ë¬¸ì œ
```python
# í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° í™•ì¸
trainable_params = [p for p in model.parameters() if p.requires_grad]
print(f"Trainable parameters: {len(trainable_params)}")
```

## ğŸš€ í™•ì¥ì„± ê³ ë ¤ì‚¬í•­

### 1. ë©€í‹° GPU ì§€ì›
```python
# DataParallel ë˜ëŠ” DistributedDataParallel
model = torch.nn.DataParallel(model)
# ë˜ëŠ”
model = torch.nn.parallel.DistributedDataParallel(model)
```

### 2. ë™ì  LoRA ë­í¬
```python
# ë ˆì´ì–´ë³„ ë‹¤ë¥¸ LoRA ë­í¬ ì ìš©
target_modules_config = {
    "mha_q_proj": {"r": 8},
    "mha_k_proj": {"r": 4}, 
    "ffnn_linear1": {"r": 16}
}
```

### 3. ì‹¤í—˜ ê´€ë¦¬
```python
# Hydraë¥¼ í†µí•œ êµ¬ì¡°í™”ëœ ì„¤ì • ê´€ë¦¬
@hydra.main(config_path="config", config_name="config")
def main(cfg: DictConfig):
    engine = Engine_v4(cfg)
```

ì´ ì•„í‚¤í…ì²˜ ê°€ì´ë“œë¥¼ í†µí•´ ì½”ë“œì˜ ì „ì²´ì ì¸ êµ¬ì¡°ì™€ ê° ì»´í¬ë„ŒíŠ¸ ê°„ì˜ ê´€ê³„ë¥¼ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.